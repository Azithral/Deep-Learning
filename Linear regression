import torch
import numpy as np
from torch.autograd import Variable
import torch.nn as nn

#DataLoading needs to be done as x_values and y_values
x_train = np.array(x_values , dtype = np.float32)
x_train = x_train.reshape(-1,1)
#define a function of y(x)
y_train = np.array(y_values , dtype = np.float32)
y_train = y_train.reshape(-1,1)

#creating the linear regression model
class LinearRegressionModel(nn.Module):
    def __init__(self, input_size,output_size):
        super(LinearRegressionModel , self).__init__()
        self.linear = nn.Linear(input_dim , output_dim)
        
    def forward(self , x):
        out = self.linear(x)
        return out


#Instantiate Model Class
input_dim =1
output_dim = 1

model = LinearRegressionModel(input_dim, output_dim)

if torch.cuda.is_available():
    model.cuda()
    
#Instantiate Loss class
criterion = nn.MSELoss()

#Instantiate Optimizer class
optimizer = torch.optim.SGD(model.parameters() , lr = 0.01)

#defining the value of epoch
epochs = 100

#Train model
for epoch in range(epochs):
        
    if torch.cuda.is_available():
        inputs = Variable(torch.from_numpy(x_train).cuda())
        labels = Variable(torch.from_numpy(y_train).cuda())
    else:
        inputs = Variable(torch.from_numpy(x_train))
        labels = Variable(torch.from_numpy(y_train))

    optimizer.zero_grad()
    
    outputs = model(inputs)
    
    loss = criterion(outputs , labels)
    
    loss.backward()
    
    optimizer.step()
    
    print('epoch {}, loss {} '.format(epoch+1 , loss.item()))


